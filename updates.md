---
layout: default
title: Model Updates and Revisions 
nav_order: 9
---
# Model Updates and Revisions 

Two potential situations where the model should be updated or revised for ethical reasons are when complaints of cyberbullying increase and when the model is used in contexts aimed at punishment instead of safety, such as law enforcement. 

First, the model will be consistently evaluated from various technical performance measures that measure accuracy, demographic parity, precision, and more. Additionally, we will supervise how many accounts are generally being flagged, how teenagers view Instagramâ€™s handling of cyberbullying through public opinion surveys, and other statistics that reveal how effective this model is on a larger, non-technical scale. If the number of false positive increases dramatically and become a nuisance for users, if complaints about cyberbullying on Instagram increase consistently or near pre-feature levels, or if another statistic that shows this model does not encapsulate cyberbullying properly, then we ought to update the model. This will include working with domain experts to understand what the relevant factors would be and how we should analyze them. 

Second, this model should be revised when it is used as a tool for punishment, especially in law enforcement. This profiling nature, network analysis, and text analysis features of this model do make it ideal to identify potential criminals, especially those who are notablly active on social media such as school shooters, radicalized terrorists, and consperiency theorists turned insurrectionists. Nevertheless, the predictors will need changed to information that is more publicly available since these targets are unlikely to cooperate. Furthermore, network predictors should have more weight predictors about criminal history ought to be collected to predict future crime. Since this use is aimed at preventing societal harm, instead of individual harm, we also ought to have more stringent thresholds and appropriate models. 
